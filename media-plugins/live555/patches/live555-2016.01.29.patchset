From 60acc27ccb584315299e57d4a1a46ce1e7ccb98e Mon Sep 17 00:00:00 2001
From: Dario Casalinuovo <b.vitruvio@gmail.com>
Date: Wed, 23 Mar 2016 19:21:17 +0000
Subject: [PATCH 1/2] Add Haiku support

---
 config.haiku | 17 +++++++++++++++++
 1 file changed, 17 insertions(+)
 create mode 100644 config.haiku

diff --git a/config.haiku b/config.haiku
new file mode 100644
index 0000000..6c12e2c
--- /dev/null
+++ b/config.haiku
@@ -0,0 +1,17 @@
+COMPILE_OPTS =		$(INCLUDES) -I. -O -DBSD=1 -DXLOCALE_NOT_USED=1 -DSOCKLEN_T=socklen_t -DHAVE_SOCKADDR_LEN=1
+C =			c
+C_COMPILER =		cc
+C_FLAGS =		$(COMPILE_OPTS)
+CPP =			cpp
+CPLUSPLUS_COMPILER =	c++
+CPLUSPLUS_FLAGS =	$(COMPILE_OPTS) -Wall
+OBJ =			o
+LINK =			c++ -o
+LINK_OPTS =		-lnetwork -L.
+CONSOLE_LINK_OPTS =	$(LINK_OPTS)
+LIBRARY_LINK =		ar cr 
+LIBRARY_LINK_OPTS =	
+LIB_SUFFIX =			a
+LIBS_FOR_CONSOLE_APPLICATION =
+LIBS_FOR_GUI_APPLICATION =
+EXE =
-- 
2.7.0


From 09f3dc767c6b7eeafc880690d191304785ed611b Mon Sep 17 00:00:00 2001
From: Dario Casalinuovo <b.vitruvio@gmail.com>
Date: Wed, 23 Mar 2016 19:23:03 +0000
Subject: [PATCH 2/2] gcc2 fixes for Haiku

---
 liveMedia/AC3AudioStreamFramer.cpp              |  2 +-
 liveMedia/AMRAudioRTPSource.cpp                 |  2 +-
 liveMedia/DVVideoStreamFramer.cpp               |  4 ++--
 liveMedia/H263plusVideoStreamParser.cpp         |  2 +-
 liveMedia/H264or5VideoRTPSink.cpp               |  2 +-
 liveMedia/H264or5VideoStreamDiscreteFramer.cpp  |  2 +-
 liveMedia/MP3ADU.cpp                            |  2 +-
 liveMedia/MPEG1or2AudioStreamFramer.cpp         |  2 +-
 liveMedia/MPEG1or2VideoStreamDiscreteFramer.cpp |  2 +-
 liveMedia/MPEG2TransportStreamFramer.cpp        |  4 ++--
 liveMedia/MPEG2TransportStreamFromESSource.cpp  |  2 +-
 liveMedia/MPEG2TransportStreamFromPESSource.cpp |  2 +-
 liveMedia/MPEG4VideoStreamDiscreteFramer.cpp    |  2 +-
 liveMedia/MPEGVideoStreamParser.cpp             |  2 +-
 liveMedia/OggFileSink.cpp                       |  2 +-
 liveMedia/ProxyServerMediaSession.cpp           |  2 +-
 liveMedia/QCELPAudioRTPSource.cpp               |  2 +-
 liveMedia/uLawAudioFilter.cpp                   | 12 ++++++------
 18 files changed, 25 insertions(+), 25 deletions(-)

diff --git a/liveMedia/AC3AudioStreamFramer.cpp b/liveMedia/AC3AudioStreamFramer.cpp
index 5800040..16036a6 100644
--- a/liveMedia/AC3AudioStreamFramer.cpp
+++ b/liveMedia/AC3AudioStreamFramer.cpp
@@ -217,7 +217,7 @@ void AC3FrameParams::setParamsFromHeader() {
 AC3AudioStreamParser
 ::AC3AudioStreamParser(AC3AudioStreamFramer* usingSource,
 			FramedSource* inputSource)
-  : StreamParser(inputSource, FramedSource::handleClosure, usingSource,
+  : StreamParser(inputSource, &FramedSource::handleClosure, usingSource,
 		 &AC3AudioStreamFramer::handleNewData, usingSource),
     fUsingSource(usingSource), fHaveParsedAFrame(False),
     fSavedFrame(NULL), fSavedFrameSize(0) {
diff --git a/liveMedia/AMRAudioRTPSource.cpp b/liveMedia/AMRAudioRTPSource.cpp
index 0f49d89..a00e6fc 100644
--- a/liveMedia/AMRAudioRTPSource.cpp
+++ b/liveMedia/AMRAudioRTPSource.cpp
@@ -474,7 +474,7 @@ void AMRDeinterleaver::doGetNextFrame() {
     fInputSource->getNextFrame(fDeinterleavingBuffer->inputBuffer(),
 			       fDeinterleavingBuffer->inputBufferSize(),
 			       afterGettingFrame, this,
-			       FramedSource::handleClosure, this);
+			       &FramedSource::handleClosure, this);
   }
 }
 
diff --git a/liveMedia/DVVideoStreamFramer.cpp b/liveMedia/DVVideoStreamFramer.cpp
index 53a0b74..1bacf84 100644
--- a/liveMedia/DVVideoStreamFramer.cpp
+++ b/liveMedia/DVVideoStreamFramer.cpp
@@ -87,7 +87,7 @@ Boolean DVVideoStreamFramer::getFrameParameters(unsigned& frameSize, double& fra
 void DVVideoStreamFramer::getProfile() {
   // To determine the stream's profile, we need to first read a chunk of data that we can parse:
   fInputSource->getNextFrame(fSavedInitialBlocks, DV_SAVED_INITIAL_BLOCKS_SIZE,
-			     afterGettingFrame, this, FramedSource::handleClosure, this);
+			     afterGettingFrame, this, &FramedSource::handleClosure, this);
   
   // Handle events until the requested data arrives:
   envir().taskScheduler().doEventLoop(&fInitialBlocksPresent);
@@ -129,7 +129,7 @@ void DVVideoStreamFramer::getAndDeliverData() {
   unsigned totBytesToDeliver = totFrameSize < fMaxSize ? totFrameSize : fMaxSize;
   unsigned numBytesToRead = totBytesToDeliver - fFrameSize;
 
-  fInputSource->getNextFrame(fTo, numBytesToRead, afterGettingFrame, this, FramedSource::handleClosure, this);
+  fInputSource->getNextFrame(fTo, numBytesToRead, afterGettingFrame, this, &FramedSource::handleClosure, this);
 }
 
 void DVVideoStreamFramer::afterGettingFrame(void* clientData, unsigned frameSize,
diff --git a/liveMedia/H263plusVideoStreamParser.cpp b/liveMedia/H263plusVideoStreamParser.cpp
index e59539f..e8fe1c2 100644
--- a/liveMedia/H263plusVideoStreamParser.cpp
+++ b/liveMedia/H263plusVideoStreamParser.cpp
@@ -29,7 +29,7 @@ H263plusVideoStreamParser::H263plusVideoStreamParser(
                               H263plusVideoStreamFramer* usingSource,
                               FramedSource* inputSource)
                               : StreamParser(inputSource,
-                                   FramedSource::handleClosure,
+                                   &FramedSource::handleClosure,
                                    usingSource,
                                    &H263plusVideoStreamFramer::continueReadProcessing,
                                    usingSource),
diff --git a/liveMedia/H264or5VideoRTPSink.cpp b/liveMedia/H264or5VideoRTPSink.cpp
index b8c16d3..5ff8e2c 100644
--- a/liveMedia/H264or5VideoRTPSink.cpp
+++ b/liveMedia/H264or5VideoRTPSink.cpp
@@ -178,7 +178,7 @@ void H264or5Fragmenter::doGetNextFrame() {
     // We have no NAL unit data currently in the buffer.  Read a new one:
     fInputSource->getNextFrame(&fInputBuffer[1], fInputBufferSize - 1,
 			       afterGettingFrame, this,
-			       FramedSource::handleClosure, this);
+			       &FramedSource::handleClosure, this);
   } else {
     // We have NAL unit data in the buffer.  There are three cases to consider:
     // 1. There is a new NAL unit in the buffer, and it's small enough to deliver
diff --git a/liveMedia/H264or5VideoStreamDiscreteFramer.cpp b/liveMedia/H264or5VideoStreamDiscreteFramer.cpp
index dae5368..cadc3ac 100644
--- a/liveMedia/H264or5VideoStreamDiscreteFramer.cpp
+++ b/liveMedia/H264or5VideoStreamDiscreteFramer.cpp
@@ -37,7 +37,7 @@ void H264or5VideoStreamDiscreteFramer::doGetNextFrame() {
   // After reading this, we'll do some parsing on the frame.
   fInputSource->getNextFrame(fTo, fMaxSize,
                              afterGettingFrame, this,
-                             FramedSource::handleClosure, this);
+                             &FramedSource::handleClosure, this);
 }
 
 void H264or5VideoStreamDiscreteFramer
diff --git a/liveMedia/MP3ADU.cpp b/liveMedia/MP3ADU.cpp
index 14c6605..86565de 100644
--- a/liveMedia/MP3ADU.cpp
+++ b/liveMedia/MP3ADU.cpp
@@ -521,7 +521,7 @@ void SegmentQueue::enqueueNewSegment(FramedSource* inputSource,
   Segment& seg = nextFreeSegment();
   inputSource->getNextFrame(seg.buf, sizeof seg.buf,
 			    sqAfterGettingSegment, this,
-			    FramedSource::handleClosure, usingSource);
+			    &FramedSource::handleClosure, usingSource);
 }
 
 void SegmentQueue::sqAfterGettingSegment(void* clientData,
diff --git a/liveMedia/MPEG1or2AudioStreamFramer.cpp b/liveMedia/MPEG1or2AudioStreamFramer.cpp
index e7539f9..61b9800 100644
--- a/liveMedia/MPEG1or2AudioStreamFramer.cpp
+++ b/liveMedia/MPEG1or2AudioStreamFramer.cpp
@@ -163,7 +163,7 @@ void MPEG1or2AudioStreamFramer::continueReadProcessing() {
 MPEG1or2AudioStreamParser
 ::MPEG1or2AudioStreamParser(MPEG1or2AudioStreamFramer* usingSource,
 			FramedSource* inputSource)
-  : StreamParser(inputSource, FramedSource::handleClosure, usingSource,
+  : StreamParser(inputSource, &FramedSource::handleClosure, usingSource,
 		 &MPEG1or2AudioStreamFramer::continueReadProcessing, usingSource) {
 }
 
diff --git a/liveMedia/MPEG1or2VideoStreamDiscreteFramer.cpp b/liveMedia/MPEG1or2VideoStreamDiscreteFramer.cpp
index 62b80ab..0a4590e 100644
--- a/liveMedia/MPEG1or2VideoStreamDiscreteFramer.cpp
+++ b/liveMedia/MPEG1or2VideoStreamDiscreteFramer.cpp
@@ -57,7 +57,7 @@ void MPEG1or2VideoStreamDiscreteFramer::doGetNextFrame() {
   // After reading this, we'll do some parsing on the frame.
   fInputSource->getNextFrame(fTo, fMaxSize,
                              afterGettingFrame, this,
-                             FramedSource::handleClosure, this);
+                             &FramedSource::handleClosure, this);
 }
 
 void MPEG1or2VideoStreamDiscreteFramer
diff --git a/liveMedia/MPEG2TransportStreamFramer.cpp b/liveMedia/MPEG2TransportStreamFramer.cpp
index 18c7fb1..09fc35a 100644
--- a/liveMedia/MPEG2TransportStreamFramer.cpp
+++ b/liveMedia/MPEG2TransportStreamFramer.cpp
@@ -116,7 +116,7 @@ void MPEG2TransportStreamFramer::doGetNextFrame() {
   fFrameSize = 0;
   fInputSource->getNextFrame(fTo, fMaxSize,
 			     afterGettingFrame, this,
-			     FramedSource::handleClosure, this);
+			     &FramedSource::handleClosure, this);
 }
 
 void MPEG2TransportStreamFramer::doStopGettingFrames() {
@@ -166,7 +166,7 @@ void MPEG2TransportStreamFramer::afterGettingFrame1(unsigned frameSize,
     fFrameSize -= syncBytePosition;
     fInputSource->getNextFrame(&fTo[fFrameSize], syncBytePosition,
 			       afterGettingFrame, this,
-			       FramedSource::handleClosure, this);
+			       &FramedSource::handleClosure, this);
     return;
   } // else normal case: the data begins with a sync byte
 
diff --git a/liveMedia/MPEG2TransportStreamFromESSource.cpp b/liveMedia/MPEG2TransportStreamFromESSource.cpp
index 4008e8b..a0ed86e 100644
--- a/liveMedia/MPEG2TransportStreamFromESSource.cpp
+++ b/liveMedia/MPEG2TransportStreamFromESSource.cpp
@@ -192,7 +192,7 @@ void InputESSourceRecord::askForNewData() {
     fInputSource->getNextFrame(&fInputBuffer[fInputBufferBytesAvailable],
                                INPUT_BUFFER_SIZE-fInputBufferBytesAvailable,
                                afterGettingFrame, this,
-                               FramedSource::handleClosure, &fParent);
+                               &FramedSource::handleClosure, &fParent);
   }
 }
 
diff --git a/liveMedia/MPEG2TransportStreamFromPESSource.cpp b/liveMedia/MPEG2TransportStreamFromPESSource.cpp
index a936800..7101a04 100644
--- a/liveMedia/MPEG2TransportStreamFromPESSource.cpp
+++ b/liveMedia/MPEG2TransportStreamFromPESSource.cpp
@@ -48,7 +48,7 @@ void MPEG2TransportStreamFromPESSource
 ::awaitNewBuffer(unsigned char* /*oldBuffer*/) {
   fInputSource->getNextFrame(fInputBuffer, MAX_PES_PACKET_SIZE,
 			     afterGettingFrame, this,
-			     FramedSource::handleClosure, this);
+			     &FramedSource::handleClosure, this);
 }
 
 void MPEG2TransportStreamFromPESSource
diff --git a/liveMedia/MPEG4VideoStreamDiscreteFramer.cpp b/liveMedia/MPEG4VideoStreamDiscreteFramer.cpp
index 7e9b97a..457ae3b 100644
--- a/liveMedia/MPEG4VideoStreamDiscreteFramer.cpp
+++ b/liveMedia/MPEG4VideoStreamDiscreteFramer.cpp
@@ -49,7 +49,7 @@ void MPEG4VideoStreamDiscreteFramer::doGetNextFrame() {
   // After reading this, we'll do some parsing on the frame.
   fInputSource->getNextFrame(fTo, fMaxSize,
                              afterGettingFrame, this,
-                             FramedSource::handleClosure, this);
+                             &FramedSource::handleClosure, this);
 }
 
 void MPEG4VideoStreamDiscreteFramer
diff --git a/liveMedia/MPEGVideoStreamParser.cpp b/liveMedia/MPEGVideoStreamParser.cpp
index 15c7d7d..380ea34 100644
--- a/liveMedia/MPEGVideoStreamParser.cpp
+++ b/liveMedia/MPEGVideoStreamParser.cpp
@@ -23,7 +23,7 @@ along with this library; if not, write to the Free Software Foundation, Inc.,
 MPEGVideoStreamParser
 ::MPEGVideoStreamParser(MPEGVideoStreamFramer* usingSource,
 			FramedSource* inputSource)
-  : StreamParser(inputSource, FramedSource::handleClosure, usingSource,
+  : StreamParser(inputSource, &FramedSource::handleClosure, usingSource,
 		 &MPEGVideoStreamFramer::continueReadProcessing, usingSource),
   fUsingSource(usingSource) {
 }
diff --git a/liveMedia/OggFileSink.cpp b/liveMedia/OggFileSink.cpp
index 61e29e5..7010ae7 100644
--- a/liveMedia/OggFileSink.cpp
+++ b/liveMedia/OggFileSink.cpp
@@ -86,7 +86,7 @@ Boolean OggFileSink::continuePlaying() {
   if (fSource == NULL) return False;
 
   fSource->getNextFrame(fBuffer, fBufferSize,
-			FileSink::afterGettingFrame, this,
+			&FileSink::afterGettingFrame, this,
 			ourOnSourceClosure, this);
   return True;
 }
diff --git a/liveMedia/ProxyServerMediaSession.cpp b/liveMedia/ProxyServerMediaSession.cpp
index daa3a35..a2f4e3c 100644
--- a/liveMedia/ProxyServerMediaSession.cpp
+++ b/liveMedia/ProxyServerMediaSession.cpp
@@ -882,5 +882,5 @@ void PresentationTimeSubsessionNormalizer::afterGettingFrame(unsigned frameSize,
 }
 
 void PresentationTimeSubsessionNormalizer::doGetNextFrame() {
-  fInputSource->getNextFrame(fTo, fMaxSize, afterGettingFrame, this, FramedSource::handleClosure, this);
+  fInputSource->getNextFrame(fTo, fMaxSize, afterGettingFrame, this, &FramedSource::handleClosure, this);
 }
diff --git a/liveMedia/QCELPAudioRTPSource.cpp b/liveMedia/QCELPAudioRTPSource.cpp
index b99cff9..84d58b2 100644
--- a/liveMedia/QCELPAudioRTPSource.cpp
+++ b/liveMedia/QCELPAudioRTPSource.cpp
@@ -346,7 +346,7 @@ void QCELPDeinterleaver::doGetNextFrame() {
     fInputSource->getNextFrame(fDeinterleavingBuffer->inputBuffer(),
 			       fDeinterleavingBuffer->inputBufferSize(),
 			       afterGettingFrame, this,
-			       FramedSource::handleClosure, this);
+			       &FramedSource::handleClosure, this);
   }
 }
 
diff --git a/liveMedia/uLawAudioFilter.cpp b/liveMedia/uLawAudioFilter.cpp
index 041e67e..8100732 100644
--- a/liveMedia/uLawAudioFilter.cpp
+++ b/liveMedia/uLawAudioFilter.cpp
@@ -55,7 +55,7 @@ void uLawFromPCMAudioSource::doGetNextFrame() {
   // Arrange to read samples into the input buffer:
   fInputSource->getNextFrame(fInputBuffer, bytesToRead,
 			     afterGettingFrame, this,
-                             FramedSource::handleClosure, this);
+                             &FramedSource::handleClosure, this);
 }
 
 void uLawFromPCMAudioSource
@@ -172,7 +172,7 @@ void PCMFromuLawAudioSource::doGetNextFrame() {
   // Arrange to read samples into the input buffer:
   fInputSource->getNextFrame(fInputBuffer, bytesToRead,
 			     afterGettingFrame, this,
-                             FramedSource::handleClosure, this);
+                             &FramedSource::handleClosure, this);
 }
 
 void PCMFromuLawAudioSource
@@ -239,7 +239,7 @@ void NetworkFromHostOrder16::doGetNextFrame() {
   // Arrange to read data directly into the client's buffer:
   fInputSource->getNextFrame(fTo, fMaxSize,
 			     afterGettingFrame, this,
-                             FramedSource::handleClosure, this);
+                             &FramedSource::handleClosure, this);
 }
 
 void NetworkFromHostOrder16
@@ -293,7 +293,7 @@ void HostFromNetworkOrder16::doGetNextFrame() {
   // Arrange to read data directly into the client's buffer:
   fInputSource->getNextFrame(fTo, fMaxSize,
 			     afterGettingFrame, this,
-                             FramedSource::handleClosure, this);
+                             &FramedSource::handleClosure, this);
 }
 
 void HostFromNetworkOrder16
@@ -346,7 +346,7 @@ void EndianSwap16::doGetNextFrame() {
   // Arrange to read data directly into the client's buffer:
   fInputSource->getNextFrame(fTo, fMaxSize,
 			     afterGettingFrame, this,
-                             FramedSource::handleClosure, this);
+                             &FramedSource::handleClosure, this);
 }
 
 void EndianSwap16::afterGettingFrame(void* clientData, unsigned frameSize,
@@ -397,7 +397,7 @@ void EndianSwap24::doGetNextFrame() {
   // Arrange to read data directly into the client's buffer:
   fInputSource->getNextFrame(fTo, fMaxSize,
 			     afterGettingFrame, this,
-                             FramedSource::handleClosure, this);
+                             &FramedSource::handleClosure, this);
 }
 
 void EndianSwap24::afterGettingFrame(void* clientData, unsigned frameSize,
-- 
2.7.0

